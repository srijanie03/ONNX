{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626c0007-8504-4d3c-b460-9dbecb1ed3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime.training.onnxblock as onnxblock\n",
    "from onnxruntime.training.api import CheckpointState, Module, Optimizer\n",
    "from onnxruntime.training import artifacts\n",
    "from onnxruntime import InferenceSession\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import onnx\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844bfc00-b9e3-49d2-a0b8-724f5eea72fd",
   "metadata": {},
   "source": [
    "## Generate forward-only graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcffa1e6-739f-45cf-bb3b-14f471d980bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch class that we will use to generate the graphs.\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNet, self).__init__()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, model_input):\n",
    "        out = self.fc1(model_input)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Create an instance.\n",
    "device = \"cpu\"\n",
    "batch_size, input_size, hidden_size, output_size = 64, 784, 500, 10\n",
    "pt_model = SimpleNet(input_size, hidden_size, output_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f1f208-e6e0-4566-84da-09a84c05a52e",
   "metadata": {},
   "source": [
    "## Freezing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "459a9bc6-0d3b-4422-8d30-e173d0b8c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pt_model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed8e94d7-41c9-4e10-9025-4897cd6dac01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  fc1.weight Requires_Grad:  True\n",
      "Name:  fc1.bias Requires_Grad:  True\n",
      "Name:  fc2.weight Requires_Grad:  True\n",
      "Name:  fc2.bias Requires_Grad:  True\n"
     ]
    }
   ],
   "source": [
    "for name, param in pt_model.named_parameters():\n",
    "    print('Name: ', name, 'Requires_Grad: ', param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f369b36b-cb5d-4b8e-8146-edbb1409b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freezing them explicitly\n",
    "pt_model.fc1.weight.requires_grad=False\n",
    "pt_model.fc1.bias.requires_grad=False\n",
    "pt_model.fc2.weight.required_grad=True\n",
    "pt_model.fc2.bias.required_grad=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cca8184-0ef0-4cca-a9b7-c42e62552202",
   "metadata": {},
   "source": [
    "## Getting the ONNX export ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed07cdcd-0582-4e20-ad3d-8ab3ed11829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random input.\n",
    "model_inputs = (torch.randn(batch_size, input_size, device=device),)\n",
    "\n",
    "model_outputs = pt_model(*model_inputs)\n",
    "if isinstance(model_outputs, torch.Tensor):\n",
    "    model_outputs = [model_outputs]\n",
    "    \n",
    "input_names = [\"input\"]\n",
    "output_names = [\"output\"]\n",
    "dynamic_axes = {\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    "\n",
    "f = io.BytesIO()\n",
    "torch.onnx.export(\n",
    "    pt_model,\n",
    "    model_inputs,\n",
    "    f,\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    opset_version=14,\n",
    "    do_constant_folding=False,\n",
    "    training=torch.onnx.TrainingMode.TRAINING,\n",
    "    dynamic_axes=dynamic_axes,\n",
    "    export_params=True,\n",
    "    keep_initializers_as_inputs=False,\n",
    ")\n",
    "onnx_model = onnx.load_model_from_string(f.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966003d-a086-45cf-88fe-a022d0611257",
   "metadata": {},
   "source": [
    "## Method 1 : Create training, eval, optimizer graph and checkpoint at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06a214ab-b786-4f04-b06b-29d1c90a0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "requires_grad = [name for name, param in pt_model.named_parameters() if param.requires_grad]\n",
    "\n",
    "frozen_params = [name for name, param in pt_model.named_parameters() if not param.requires_grad]\n",
    "\n",
    "artifacts.generate_artifacts(\n",
    "    onnx_model,\n",
    "    optimizer=artifacts.OptimType.AdamW,\n",
    "    #loss=artifacts.LossType.CrossEntropyLoss, #Specify the loss function, try with different ones\n",
    "    loss=artifacts.LossType.MSELoss,\n",
    "    requires_grad=requires_grad,\n",
    "    frozen_params=frozen_params,\n",
    "    artifact_directory=\"SimpleNet\",\n",
    "    additional_output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce73aea6-ad52-425a-ba4b-d6a1cb3128d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model :\n",
      "\n",
      "graph main_graph (\n",
      "  %input[FLOAT, batch_sizex784]\n",
      "  %target[FLOAT, batch_sizex10]\n",
      "  %fc1.weight[FLOAT, 500x784]\n",
      "  %fc1.bias[FLOAT, 500]\n",
      "  %fc2.weight[FLOAT, 10x500]\n",
      "  %fc2.bias[FLOAT, 10]\n",
      "  %fc2.weight_grad.accumulation.buffer[FLOAT, 10x500]\n",
      "  %fc2.bias_grad.accumulation.buffer[FLOAT, 10]\n",
      "  %lazy_reset_grad[BOOL, 1]\n",
      ") initializers (\n",
      "  %onnx::pow_exponent::73[FLOAT, 1]\n",
      "  %onnx::reducemean_output::76_grad[FLOAT, scalar]\n",
      "  %/fc2/Gemm_Grad/ReduceAxes_for_/fc2/Gemm_Grad/dC_reduced[INT64, 1]\n",
      "  %OneConstant_Type1[FLOAT, 1]\n",
      ") {\n",
      "  %/fc1/Gemm_output_0 = Gemm[alpha = 1, beta = 1, transA = 0, transB = 1](%input, %fc1.weight, %fc1.bias)\n",
      "  %/relu/Relu_output_0 = Relu(%/fc1/Gemm_output_0)\n",
      "  %output = Gemm[alpha = 1, beta = 1, transA = 0, transB = 1](%/relu/Relu_output_0, %fc2.weight, %fc2.bias)\n",
      "  %onnx::sub_output::71 = Sub(%output, %target)\n",
      "  %onnx::pow_output::74 = Pow(%onnx::sub_output::71, %onnx::pow_exponent::73)\n",
      "  %onnx::ReduceMean::77_Grad/Sized_X = Size(%onnx::pow_output::74)\n",
      "  %onnx::ReduceMean::77_Grad/Shaped_X = Shape(%onnx::pow_output::74)\n",
      "  %onnx::ReduceMean::77_Grad/Sized_Grad = Size(%onnx::reducemean_output::76_grad)\n",
      "  %onnx::ReduceMean::77_Grad/Scale = Div(%onnx::ReduceMean::77_Grad/Sized_X, %onnx::ReduceMean::77_Grad/Sized_Grad)\n",
      "  %onnx::ReduceMean::77_Grad/Scaled_Grad = Scale[scale_down = 1](%onnx::reducemean_output::76_grad, %onnx::ReduceMean::77_Grad/Scale)\n",
      "  %onnx::pow_output::74_grad = Expand(%onnx::ReduceMean::77_Grad/Scaled_Grad, %onnx::ReduceMean::77_Grad/Shaped_X)\n",
      "  %onnx::Pow::75_Grad/Sub_I1 = Sub(%onnx::pow_exponent::73, %OneConstant_Type1)\n",
      "  %onnx::Pow::75_Grad/Pow_I0 = Pow(%onnx::sub_output::71, %onnx::Pow::75_Grad/Sub_I1)\n",
      "  %onnx::Pow::75_Grad/Mul_Pow_I0_I1 = Mul(%onnx::Pow::75_Grad/Pow_I0, %onnx::pow_exponent::73)\n",
      "  %onnx::sub_output::71_grad = Mul(%onnx::Pow::75_Grad/Mul_Pow_I0_I1, %onnx::pow_output::74_grad)\n",
      "  %output_grad = Identity(%onnx::sub_output::71_grad)\n",
      "  %/fc2/Gemm_Grad/dC_reduced = ReduceSum[keepdims = 0, noop_with_empty_axes = 0](%output_grad, %/fc2/Gemm_Grad/ReduceAxes_for_/fc2/Gemm_Grad/dC_reduced)\n",
      "  %fc2.bias_grad = Identity(%/fc2/Gemm_Grad/dC_reduced)\n",
      "  %fc2.weight_grad = Gemm[alpha = 1, beta = 0, transA = 1, transB = 0](%output_grad, %/relu/Relu_output_0)\n",
      "  %onnx::reducemean_output::76 = ReduceMean[keepdims = 0](%onnx::pow_output::74)\n",
      "  %fc2.weight_grad.accumulation.out = InPlaceAccumulatorV2(%fc2.weight_grad.accumulation.buffer, %fc2.weight_grad, %lazy_reset_grad)\n",
      "  %fc2.bias_grad.accumulation.out = InPlaceAccumulatorV2(%fc2.bias_grad.accumulation.buffer, %fc2.bias_grad, %lazy_reset_grad)\n",
      "  return %onnx::reducemean_output::76, %output, %fc2.weight_grad.accumulation.out, %fc2.bias_grad.accumulation.out\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model = onnx.load(\"SimpleNET/training_model.onnx\")\n",
    "print('Model :\\n\\n{}'.format(onnx.helper.printable_graph(model.graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1ac4e00-69b5-4062-82d5-e04caf425e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias']\n"
     ]
    }
   ],
   "source": [
    "print ([name for name,param in pt_model.named_parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e5bd6-330e-4b88-8706-16898a8ddd6b",
   "metadata": {},
   "source": [
    "## Method 2 : Create training, eval, optimizer graph and checkpoint separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f318b13-4378-47f0-9eca-aeea867b4838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a class with a Loss function.\n",
    "class SimpleNetTrainingBlock(onnxblock.TrainingBlock):\n",
    "    def __init__(self):\n",
    "        super(SimpleNetTrainingBlock, self).__init__()\n",
    "        self.loss = onnxblock.loss.CrossEntropyLoss() #try a different loss\n",
    "\n",
    "    def build(self, output_name):\n",
    "        return self.loss(output_name), output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276df954-1e03-4e8f-8d5f-70ee067a3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the onnx model with loss\n",
    "training_block = SimpleNetTrainingBlock()\n",
    "for param in onnx_model.graph.initializer:\n",
    "    print(param.name)\n",
    "    training_block.requires_grad(param.name, True)\n",
    "\n",
    "# Building training graph and eval graph.\n",
    "model_params = None\n",
    "with onnxblock.base(onnx_model):\n",
    "    _ = training_block(*[output.name for output in onnx_model.graph.output])\n",
    "    training_model, eval_model = training_block.to_model_proto()\n",
    "    model_params = training_block.parameters()\n",
    "\n",
    "# Building the optimizer graph\n",
    "optimizer_block = onnxblock.optim.AdamW()\n",
    "with onnxblock.empty_base() as accessor:\n",
    "    _ = optimizer_block(model_params)\n",
    "    optimizer_model = optimizer_block.to_model_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90ca32-dc4f-4f3e-822b-06bb3e95a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the training graph\n",
    "onnx.save(training_model, \"training_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07fe901-08e6-4542-a271-d75990ffd49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If needed\n",
    "onnx.save(optimizer_model, \"optimizer_model.onnx\")\n",
    "onnx.save(eval_model, \"eval_model.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
