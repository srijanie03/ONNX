{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4b3f5f-b3e4-415c-9461-4149635cb86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime.training.onnxblock as onnxblock\n",
    "from onnxruntime.training.api import CheckpointState, Module, Optimizer\n",
    "from onnxruntime.training import artifacts\n",
    "from onnxruntime import InferenceSession\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnx\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a721d06-4dec-448f-bb7f-8ad915b5e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        \n",
    "        attn_scores = queries @ keys.T # omega\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94094065-e2de-486c-958a-21882992ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71bfd4a7-6fb9-400d-a79b-fa06f3707542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#x_2 = inputs[1] # second input element\n",
    "d_in = inputs.shape[1] # the input embedding size, d=3\n",
    "d_out = 2 # the output embedding size, d=2\n",
    "batch_size=1\n",
    "print(d_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f963952-2a76-4c7f-b457-daf3e54f0da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "device = \"cpu\"\n",
    "sa = SelfAttention(d_in, d_out).to(device)\n",
    "print(sa(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fc7e749-dfd6-465d-8126-360aeab50fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = sa(inputs)\n",
    "if isinstance(model_outputs, torch.Tensor):\n",
    "    model_outputs = [model_outputs]\n",
    "    \n",
    "input_names = [\"input\"]\n",
    "output_names = [\"output\"]\n",
    "dynamic_axes = {\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff72760-5ed1-4292-9796-e076cd45bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = io.BytesIO()\n",
    "torch.onnx.export(\n",
    "    sa,\n",
    "    inputs,\n",
    "    f,\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    opset_version=14,\n",
    "    do_constant_folding=False,\n",
    "    training=torch.onnx.TrainingMode.TRAINING,\n",
    "    dynamic_axes=dynamic_axes,\n",
    "    export_params=True,\n",
    "    keep_initializers_as_inputs=False,\n",
    ")\n",
    "onnx_model = onnx.load_model_from_string(f.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f032f1-841e-46ea-8f11-5fc15263015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "requires_grad = [name for name, param in sa.named_parameters() if param.requires_grad]\n",
    "\n",
    "frozen_params = [name for name, param in sa.named_parameters() if not param.requires_grad]\n",
    "\n",
    "artifacts.generate_artifacts(\n",
    "    onnx_model,\n",
    "    optimizer=artifacts.OptimType.AdamW,\n",
    "    #loss=artifacts.LossType.CrossEntropyLoss, #Specify the loss function, try with different ones\n",
    "    loss=artifacts.LossType.MSELoss,\n",
    "    requires_grad=requires_grad,\n",
    "    frozen_params=frozen_params,\n",
    "    artifact_directory=\"Attention\",\n",
    "    additional_output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23c9812e-188b-47bf-bc6f-7ae6b947c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model :\n",
      "\n",
      "graph main_graph (\n",
      "  %input[FLOAT, batch_sizex3]\n",
      "  %target[FLOAT, batch_sizex2]\n",
      "  %W_query[FLOAT, 3x2]\n",
      "  %W_key[FLOAT, 3x2]\n",
      "  %W_value[FLOAT, 3x2]\n",
      "  %W_query_grad.accumulation.buffer[FLOAT, 3x2]\n",
      "  %W_key_grad.accumulation.buffer[FLOAT, 3x2]\n",
      "  %W_value_grad.accumulation.buffer[FLOAT, 3x2]\n",
      "  %lazy_reset_grad[BOOL, 1]\n",
      ") initializers (\n",
      "  %onnx::pow_exponent::3[FLOAT, 1]\n",
      "  %/Pow_output_0[FLOAT, scalar]\n",
      "  %onnx::reducemean_output::6_grad[FLOAT, scalar]\n",
      "  %OneConstant_Type1[FLOAT, 1]\n",
      ") {\n",
      "  %/MatMul_2_output_0 = MatMul(%input, %W_value)\n",
      "  %/MatMul_1_output_0 = MatMul(%input, %W_query)\n",
      "  %/MatMul_output_0 = MatMul(%input, %W_key)\n",
      "  %/Transpose_output_0 = Transpose[perm = [1, 0]](%/MatMul_output_0)\n",
      "  %/MatMul_3_output_0 = MatMul(%/MatMul_1_output_0, %/Transpose_output_0)\n",
      "  %/Div_output_0 = Div(%/MatMul_3_output_0, %/Pow_output_0)\n",
      "  %/Softmax_output_0 = Softmax[axis = -1](%/Div_output_0)\n",
      "  %output = MatMul(%/Softmax_output_0, %/MatMul_2_output_0)\n",
      "  %onnx::sub_output::1 = Sub(%output, %target)\n",
      "  %onnx::pow_output::4 = Pow(%onnx::sub_output::1, %onnx::pow_exponent::3)\n",
      "  %onnx::ReduceMean::7_Grad/Sized_X = Size(%onnx::pow_output::4)\n",
      "  %onnx::ReduceMean::7_Grad/Shaped_X = Shape(%onnx::pow_output::4)\n",
      "  %onnx::ReduceMean::7_Grad/Sized_Grad = Size(%onnx::reducemean_output::6_grad)\n",
      "  %onnx::ReduceMean::7_Grad/Scale = Div(%onnx::ReduceMean::7_Grad/Sized_X, %onnx::ReduceMean::7_Grad/Sized_Grad)\n",
      "  %onnx::ReduceMean::7_Grad/Scaled_Grad = Scale[scale_down = 1](%onnx::reducemean_output::6_grad, %onnx::ReduceMean::7_Grad/Scale)\n",
      "  %onnx::pow_output::4_grad = Expand(%onnx::ReduceMean::7_Grad/Scaled_Grad, %onnx::ReduceMean::7_Grad/Shaped_X)\n",
      "  %onnx::Pow::5_Grad/Sub_I1 = Sub(%onnx::pow_exponent::3, %OneConstant_Type1)\n",
      "  %onnx::Pow::5_Grad/Pow_I0 = Pow(%onnx::sub_output::1, %onnx::Pow::5_Grad/Sub_I1)\n",
      "  %onnx::Pow::5_Grad/Mul_Pow_I0_I1 = Mul(%onnx::Pow::5_Grad/Pow_I0, %onnx::pow_exponent::3)\n",
      "  %onnx::sub_output::1_grad = Mul(%onnx::Pow::5_Grad/Mul_Pow_I0_I1, %onnx::pow_output::4_grad)\n",
      "  %output_grad = Identity(%onnx::sub_output::1_grad)\n",
      "  %/MatMul_2_output_0_grad = Gemm[alpha = 1, beta = 0, transA = 1, transB = 0](%/Softmax_output_0, %output_grad)\n",
      "  %W_value_grad = Gemm[alpha = 1, beta = 0, transA = 1, transB = 0](%input, %/MatMul_2_output_0_grad)\n",
      "  %/Softmax_output_0_grad = Gemm[alpha = 1, beta = 0, transA = 0, transB = 1](%output_grad, %/MatMul_2_output_0)\n",
      "  %/Div_output_0_grad = SoftmaxGrad_13[axis = -1](%/Softmax_output_0_grad, %/Softmax_output_0)\n",
      "  %/Div_Grad/PreReduceGrad0 = Div(%/Div_output_0_grad, %/Pow_output_0)\n",
      "  %/MatMul_3_output_0_grad = Identity(%/Div_Grad/PreReduceGrad0)\n",
      "  %/MatMul_1_output_0_grad = Gemm[alpha = 1, beta = 0, transA = 0, transB = 1](%/MatMul_3_output_0_grad, %/Transpose_output_0)\n",
      "  %W_query_grad = Gemm[alpha = 1, beta = 0, transA = 1, transB = 0](%input, %/MatMul_1_output_0_grad)\n",
      "  %/Transpose_output_0_grad = Gemm[alpha = 1, beta = 0, transA = 1, transB = 0](%/MatMul_1_output_0, %/MatMul_3_output_0_grad)\n",
      "  %/MatMul_output_0_grad = Transpose[perm = [1, 0]](%/Transpose_output_0_grad)\n",
      "  %W_key_grad = Gemm[alpha = 1, beta = 0, transA = 1, transB = 0](%input, %/MatMul_output_0_grad)\n",
      "  %onnx::reducemean_output::6 = ReduceMean[keepdims = 0](%onnx::pow_output::4)\n",
      "  %W_query_grad.accumulation.out = InPlaceAccumulatorV2(%W_query_grad.accumulation.buffer, %W_query_grad, %lazy_reset_grad)\n",
      "  %W_key_grad.accumulation.out = InPlaceAccumulatorV2(%W_key_grad.accumulation.buffer, %W_key_grad, %lazy_reset_grad)\n",
      "  %W_value_grad.accumulation.out = InPlaceAccumulatorV2(%W_value_grad.accumulation.buffer, %W_value_grad, %lazy_reset_grad)\n",
      "  return %onnx::reducemean_output::6, %output, %W_query_grad.accumulation.out, %W_key_grad.accumulation.out, %W_value_grad.accumulation.out\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model = onnx.load(\"Attention/training_model.onnx\")\n",
    "print('Model :\\n\\n{}'.format(onnx.helper.printable_graph(model.graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22919204-d1d1-46b6-b1de-1618fea9af2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W_query', 'W_key', 'W_value']\n"
     ]
    }
   ],
   "source": [
    "print(requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87a7c677-bf12-4900-ae98-9c0230671df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(frozen_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
